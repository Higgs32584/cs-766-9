{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. [20 pts] In this assignment, we will update our pipeline to extract keywords that specifically help to differentiate between reviews labeled as sentiment 0 and reviews labeled as sentiment 1. First, remove HTML specific keywords, apply your favorite way of tokenizing and use Tf-Idf features to classify reviews using an SVM classifier. Report the 10-fold CV performance. (Hint: Aim 90% plus performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "import re\n",
    "import nltk\n",
    "# Import necessary libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Add custom words to the set\n",
    "custom_words = ['br','the', 'of','to','in','that','and','he','is','it']\n",
    "for word in custom_words:\n",
    "    stop_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ie_preprocess(document):\n",
    "    # Sentence Parse\n",
    "    document = re.sub('<br />', '', document)\n",
    "    document = re.sub(r'[^\\w\\s]', '', document)\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    \n",
    "    # Word Parse and remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [[word for word in sent if word.lower() not in stop_words and len(word) > 2] for sent in sentences]\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [[1974, teenager, Martha, Moxley, Maggie, Grac...\n",
       "1        [[really, like, Kris, Kristofferson, usual, ea...\n",
       "2        [[SPOILER, read, think, watching, movie, altho...\n",
       "3        [[people, seen, wonderful, movie, sure, thet, ...\n",
       "4        [[recently, bought, DVD, forgetting, much, hat...\n",
       "                               ...                        \n",
       "49995    [[lets, start, best, building, although, hard,...\n",
       "49996    [[British, heritage, film, industry, control, ...\n",
       "49997    [[dont, even, know, begin, one, family, worst,...\n",
       "49998    [[Richard, Tyler, little, boy, scared, everyth...\n",
       "49999    [[waited, long, watch, movie, Also, like, Bruc...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './movie_data.csv'\n",
    "\n",
    "df = pd.read_csv(path, encoding=\"utf-8\")\n",
    "df['review'].apply(ie_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cross_val_score() got an unexpected keyword argument 'dual'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/cs-766-9/Michael_Higgins_Assignment#9.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfriendly-xylophone-757j579q5x9fxw94/workspaces/cs-766-9/Michael_Higgins_Assignment%239.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m log_classifier \u001b[39m=\u001b[39m LinearSVC()\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfriendly-xylophone-757j579q5x9fxw94/workspaces/cs-766-9/Michael_Higgins_Assignment%239.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m cv \u001b[39m=\u001b[39m StratifiedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bfriendly-xylophone-757j579q5x9fxw94/workspaces/cs-766-9/Michael_Higgins_Assignment%239.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m scores \u001b[39m=\u001b[39m cross_val_score(log_classifier, X, y, cv\u001b[39m=\u001b[39;49mcv, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m,dual\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfriendly-xylophone-757j579q5x9fxw94/workspaces/cs-766-9/Michael_Higgins_Assignment%239.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Report the 10-fold cross-validation performance\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfriendly-xylophone-757j579q5x9fxw94/workspaces/cs-766-9/Michael_Higgins_Assignment%239.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m mean_accuracy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(scores)\n",
      "\u001b[0;31mTypeError\u001b[0m: cross_val_score() got an unexpected keyword argument 'dual'"
     ]
    }
   ],
   "source": [
    "# Create a CountVectorizer for text data\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Prepare your features and labels\n",
    "X = tfidf_vectorizer.fit_transform(df['review'])\n",
    "y = df['sentiment']\n",
    "# Transform the training data using the CountVectorizer\n",
    "\n",
    "# Initialize and train the Logistic Regression classifier\n",
    "\n",
    "#SVM was too slow my computer took too long\n",
    "log_classifier = LinearSVC()\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(log_classifier, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Report the 10-fold cross-validation performance\n",
    "mean_accuracy = np.mean(scores)\n",
    "print(\"Mean Accuracy:\", mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. [20 pts] Rank the first 10 keywords that indicate the difference between the classes 0 and 1 (i.e., 10 words for sentiment 0, and 10 words for sentiment 1).\n",
    "#### (Hint: Use the classifier coef_ field, consult the scikit-learn API if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords for Best:\n",
      "#1, excellent: 4.026698778286953\n",
      "#2, great: 3.6040472361043303\n",
      "#3, perfect: 3.4247399655035737\n",
      "#4, refreshing: 3.020334847658237\n",
      "#5, today: 2.999946166693743\n",
      "#6, wonderful: 2.8764745245509435\n",
      "#7, enjoyable: 2.816545075386197\n",
      "#8, amazing: 2.7022374965444023\n",
      "#9, hilarious: 2.6728862919206637\n",
      "#10, brilliant: 2.6627572805013484\n",
      "\n",
      "Keywords for Worst:\n",
      "#1, worst: -6.30897808007753\n",
      "#2, waste: -5.084048478808138\n",
      "#3, awful: -4.721001754762347\n",
      "#4, boring: -4.159115585293118\n",
      "#5, disappointment: -3.870624803293975\n",
      "#6, fails: -3.6488816302643583\n",
      "#7, terrible: -3.599614638171832\n",
      "#8, poor: -3.544712368363313\n",
      "#9, disappointing: -3.460399802424631\n",
      "#10, horrible: -3.3207839064586593\n"
     ]
    }
   ],
   "source": [
    "# Extract the coefficients and feature names\n",
    "log_classifier.fit(X,y)\n",
    "\n",
    "coefficients = log_classifier.coef_[0]\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "feature_coefficients = list(zip(feature_names, coefficients))\n",
    "\n",
    "# Sort the feature coefficients\n",
    "sorted_feature_coefficients = sorted(feature_coefficients, key=lambda x: x[1])\n",
    "\n",
    "# Print the top and bottom coefficients\n",
    "def print_top_and_bottom_coefs(sorted_feature_coefficients, num_top=10):\n",
    "    print(\"Keywords for Best:\")\n",
    "    for i, (feature, coefficient) in enumerate(sorted_feature_coefficients[-num_top:][::-1]):\n",
    "        print(f\"#{i+1}, {feature}: {coefficient}\")\n",
    "\n",
    "    print(\"\\nKeywords for Worst:\")\n",
    "    for i, (feature, coefficient) in enumerate(sorted_feature_coefficients[:num_top]):\n",
    "        print(f\"#{i+1}, {feature}: {coefficient}\")\n",
    "\n",
    "print_top_and_bottom_coefs(sorted_feature_coefficients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. [20 pts] Using the results in (2.) list two pairs of words that can be sentimental antonyms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best and Worst can both be sentimental antonyms as well as terrible and brilliant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. [20 pts] Cluster the reviews into two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N data points= 50000, M features= 101895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "print(f'N data points= {X.shape[0]}, M features= {X.shape[1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report the size of the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Clusters = KMeans(n_clusters=2, random_state=20, n_init=10).fit(X)\n",
    "Counter(Clusters.labels_)\n",
    "y_ground = Clusters.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the cluster IDs as the ground truth, classify and report the 10-fold CV classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9837999999999999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(LinearSVC(), X, y_ground, cv=cv, scoring='accuracy')\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considering the results in this problem and your results, do you support using the method of clustering for sentiments when a ground truth is not available?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the results in this problem, I do support the method of clustering for sentiments when ground truth is not avaiable. While the ground truth is not entirely accurate, it is a good indicator of what the correct answer is. A model that was able to predict the actual ground truth at 90% was able to predict the simulated ground truth at nearly 100%. This indicates some level of benefit to mapping unseen data, as the actual ground truth was not far off from the simulated ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. [20 pts] Compare the top 10 keywords as generated in (2.) and then comment about these new keywords? Now have a look at the results, notice that clustering and the given sentiment classes are completely different. Do you have any suggestions about automatic labeling of reviews? Perhaps one way could be assigning class labels according to some offline positive and negative keywords. Outline an approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords for Best:\n",
      "#1, br: 31.047357646055904\n",
      "#2, the: 16.18957161950414\n",
      "#3, of: 6.017721950187207\n",
      "#4, to: 5.3504105453229664\n",
      "#5, in: 4.137673089842074\n",
      "#6, that: 4.075721682992671\n",
      "#7, and: 3.8328570608025294\n",
      "#8, he: 3.1985988501207205\n",
      "#9, is: 3.078283518956929\n",
      "#10, it: 2.52955987862024\n",
      "\n",
      "Keywords for Worst:\n",
      "#1, weren: -1.0234126221661974\n",
      "#2, oliver: -0.969345766766179\n",
      "#3, werewolf: -0.8914495685983678\n",
      "#4, propaganda: -0.8562043090716025\n",
      "#5, freedom: -0.8399016940342013\n",
      "#6, concentrates: -0.8326535524452353\n",
      "#7, truck: -0.8259538979617969\n",
      "#8, boxing: -0.8238037737376392\n",
      "#9, 70: -0.8148036872395056\n",
      "#10, bone: -0.8120330324767976\n"
     ]
    }
   ],
   "source": [
    "# Extract the coefficients and feature names\n",
    "cluster_fitted=LinearSVC().fit(X,y_ground)\n",
    "\n",
    "coefficients = cluster_fitted.coef_[0]\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "feature_coefficients = list(zip(feature_names, coefficients))\n",
    "\n",
    "# Sort the feature coefficients\n",
    "sorted_feature_coefficients = sorted(feature_coefficients, key=lambda x: x[1])\n",
    "\n",
    "# Print the top and bottom coefficients\n",
    "def print_top_and_bottom_coefs(sorted_feature_coefficients, num_top=10):\n",
    "    print(\"Keywords for Best:\")\n",
    "    for i, (feature, coefficient) in enumerate(sorted_feature_coefficients[-num_top:][::-1]):\n",
    "        print(f\"#{i+1}, {feature}: {coefficient}\")\n",
    "\n",
    "    print(\"\\nKeywords for Worst:\")\n",
    "    for i, (feature, coefficient) in enumerate(sorted_feature_coefficients[:num_top]):\n",
    "        print(f\"#{i+1}, {feature}: {coefficient}\")\n",
    "\n",
    "print_top_and_bottom_coefs(sorted_feature_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
