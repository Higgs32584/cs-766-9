{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. [20 pts] In this assignment, we will update our pipeline to extract keywords that specifically help to differentiate between reviews labeled as sentiment 0 and reviews labeled as sentiment 1. First, remove HTML specific keywords, apply your favorite way of tokenizing and use Tf-Idf features to classify reviews using an SVM classifier. Report the 10-fold CV performance. (Hint: Aim 90% plus performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import re\n",
    "import nltk\n",
    "# Import necessary libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ie_preprocess(document):\n",
    "    # Sentence Parse\n",
    "    document = re.sub('<br />', '', document)\n",
    "    document = re.sub(r'[^\\w\\s]', '', document)\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    \n",
    "    # Word Parse and remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [[word for word in sent if word.lower() not in stop_words] for sent in sentences]\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [[1974, teenager, Martha, Moxley, Maggie, Grac...\n",
       "1        [[OK, really, like, Kris, Kristofferson, usual...\n",
       "2        [[SPOILER, read, think, watching, movie, altho...\n",
       "3        [[hi, people, seen, wonderful, movie, im, sure...\n",
       "4        [[recently, bought, DVD, forgetting, much, hat...\n",
       "                               ...                        \n",
       "49995    [[OK, lets, start, best, building, although, h...\n",
       "49996    [[British, heritage, film, industry, control, ...\n",
       "49997    [[dont, even, know, begin, one, family, worst,...\n",
       "49998    [[Richard, Tyler, little, boy, scared, everyth...\n",
       "49999    [[waited, long, watch, movie, Also, like, Bruc...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './movie_data.csv'\n",
    "\n",
    "df = pd.read_csv(path, encoding=\"utf-8\")\n",
    "df['review'].apply(ie_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.8985200000000001\n"
     ]
    }
   ],
   "source": [
    "# Create a CountVectorizer for text data\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Prepare your features and labels\n",
    "X = tfidf_vectorizer.fit_transform(df['review'])\n",
    "y = df['sentiment']\n",
    "# Transform the training data using the CountVectorizer\n",
    "\n",
    "# Initialize and train the Logistic Regression classifier\n",
    "\n",
    "#SVM was too slow my computer took too long\n",
    "log_classifier = LogisticRegression(max_iter=1000)\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(log_classifier, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Report the 10-fold cross-validation performance\n",
    "mean_accuracy = np.mean(scores)\n",
    "print(\"Mean Accuracy:\", mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.89846\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. [20 pts] Rank the first 10 keywords that indicate the difference between the classes 0 and 1 (i.e., 10 words for sentiment 0, and 10 words for sentiment 1).\n",
    "#### (Hint: Use the classifier coef_ field, consult the scikit-learn API if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords for Best:\n",
      "#1, great: 9.127518653723115\n",
      "#2, excellent: 8.090241311712196\n",
      "#3, best: 6.113411362054497\n",
      "#4, perfect: 6.062811038307453\n",
      "#5, wonderful: 5.6953862208981025\n",
      "#6, amazing: 5.4603758236816295\n",
      "#7, loved: 5.029862392170517\n",
      "#8, today: 4.959431171316908\n",
      "#9, brilliant: 4.843816644909755\n",
      "#10, enjoyed: 4.7478434792514985\n",
      "\n",
      "Keywords for Worst:\n",
      "#1, worst: -11.908592211252717\n",
      "#2, bad: -9.37669364710265\n",
      "#3, awful: -8.70671904307931\n",
      "#4, waste: -8.507849207199447\n",
      "#5, boring: -8.002396674762371\n",
      "#6, poor: -7.050906745114649\n",
      "#7, terrible: -7.019335497621038\n",
      "#8, nothing: -6.2169962595996315\n",
      "#9, worse: -5.674746285129455\n",
      "#10, dull: -5.64338965296613\n"
     ]
    }
   ],
   "source": [
    "# Extract the coefficients and feature names\n",
    "log_classifier.fit(X,y)\n",
    "\n",
    "coefficients = log_classifier.coef_[0]\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "feature_coefficients = list(zip(feature_names, coefficients))\n",
    "\n",
    "# Sort the feature coefficients\n",
    "sorted_feature_coefficients = sorted(feature_coefficients, key=lambda x: x[1])\n",
    "\n",
    "# Print the top and bottom coefficients\n",
    "def print_top_and_bottom_coefs(sorted_feature_coefficients, num_top=10):\n",
    "    print(\"Keywords for Best:\")\n",
    "    for i, (feature, coefficient) in enumerate(sorted_feature_coefficients[-num_top:][::-1]):\n",
    "        print(f\"#{i+1}, {feature}: {coefficient}\")\n",
    "\n",
    "    print(\"\\nKeywords for Worst:\")\n",
    "    for i, (feature, coefficient) in enumerate(sorted_feature_coefficients[:num_top]):\n",
    "        print(f\"#{i+1}, {feature}: {coefficient}\")\n",
    "\n",
    "print_top_and_bottom_coefs(sorted_feature_coefficients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. [20 pts] Using the results in (2.) list two pairs of words that can be sentimental antonyms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best and Worst can both be sentimental antonyms as well as terrible and brilliant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. [20 pts] Cluster the reviews into two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N data points= 50000, M features= 101895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "print(f'N data points= {X.shape[0]}, M features= {X.shape[1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report the size of the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Clusters = KMeans(n_clusters=2, random_state=20, n_init=10).fit(X)\n",
    "Counter(Clusters.labels_)\n",
    "y_ground = Clusters.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the cluster IDs as the ground truth, classify and report the 10-fold CV classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(LogisticRegression(), X, y_ground, cv=cv, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99014"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considering the results in this problem and your results, do you support using the method of clustering for sentiments when a ground truth is not available?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the results in this problem, I do support the method of clustering for sentiments when ground truth is not avaiable. While the ground truth is not entirely accurate, it is a good indicator of what the correct answer is. A model that was able to predict the actual ground truth at 90% was able to predict the simulated ground truth at nearly 100%. This indicates some level of benefit to mapping unseen data, as the actual ground truth was not far off from the simulated ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. [20 pts] Compare the top 10 keywords as generated in (2.) and then comment about these new keywords? Now have a look at the results, notice that clustering and the given sentiment classes are completely different. Do you have any suggestions about automatic labeling of reviews? Perhaps one way could be assigning class labels according to some offline positive and negative keywords. Outline an approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_fitted=Clusters.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1 center:\n",
      "['the', 'and', 'of', 'to', 'it', 'is', 'this', 'in', 'movie', 'that']\n",
      "Cluster 2 center:\n",
      "['the', 'br', 'and', 'of', 'to', 'is', 'it', 'in', 'that', 'this']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Create and fit the K-Means model\n",
    "# Extract cluster centers (feature values) and feature names\n",
    "cluster_centers = cluster_fitted.cluster_centers_  # Each row represents a cluster center\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "cluster_centers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
